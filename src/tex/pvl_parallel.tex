
\chapter{Parallel Programming in PVL}


\section{Introduction}

The PVL language supports a generic quantified \emph{parallel block}.
The parallel block is meant as an easy way of writing code that
will be executed by a number of threads that is specified by
the user. Within a parallel block two forms of atomic operations
are allowed: an \emph{atomic block}, which is a section of
code executed by one thread, and a \emph{barrier} which synchonizes
the execution of all threads in the parallel block. This barrier
has a block of statements that is executed once all thread have entered the barrier
and before the first thread leaves.

For the execution of the parallel block we have two models in mind:
Java and OpenCL. The Java mapping uses a lock to implement atomic blocks
and a CyclicBarrier to implement the barrier. Hence for the Java mapping
there are no restricitons on what can be written inside an atomic block
and what may be writtin in the statement block of the barrier.
The openCL mapping transforms a parallel block into a single workgroup.
Atomic blocks have to map to local atomic operations, which means
that each atomic block may contains at most one non-ghost statement
and this statement has to be a valid atomic operation.
The barrier has to map to the OpenCL barrier, which means that
all statements in the barrier have to be ghost statements.

\section{Constructs}

The PVL language is equiped with several constructs that allow
parallel programming.

To start a parametric number of threads,
the \lstinline+par+ construct is used:
\begin{lstlisting}
par(int i = 0 .. N, j = 0 .. N){
  matrix[i][[j]=0;
}
\end{lstlisting}

It is future work to also allow multiple blocks to be started
in parallel:
\begin{lstlisting}
par {
  x = x + 1 ;
} and {
  y = y + 1 ;
}
\end{lstlisting}

To synchronize between the threads of a parallel block, we use the barrier statement.
\begin{lstlisting}
int x;
par name(int i = 0 .. N){
  a[i]=0;
  barrier(name) {
    x = x + 1;
  }
  b[i]=1;
}
\end{lstlisting}
Due to the statements in the barriers, they can only be used in
a divergence free context.

The language also supports atomic operations using atomic blocks.
For example:
\begin{lstlisting}
int x=0;
par(int i = 0 .. N){
  atomic {
    x = x + a[i];
  }
}
\end{lstlisting}

For use with atomics, we have invariant blocks, which establish invariants
that can only be broken inside atomic blocks and barriers.
\begin{lstlisting}
int x=0;
int y=1;
int z=1;
invariant inv(x+y==z){
  atomic(inv){
    int tmp=x;
    x=y;
    y=tmp;
  }
}
\end{lstlisting}

Finally, there is support for vector programming using vector blocks.
A vector blocks is a parallel construct that quantifies over a single
iteration variable, with the intended meaning that every statement is
the block is executed for all possible values at once.

For example, the following vector block adds the vectors b and c
and puts the result in a and then swaps the contents of b and c.
\begin{lstlisting}
vec(int i=0..N){
  a[i]=b[i]+c[i];
  int tmp;
  tmp=b[i];
  b[i]=c[i];
  c[i]=tmp;
}
\end{lstlisting}
Note that tmp is declared as a scalar. The encoding pass for a vector block
turns all statements into vector statements. Thus only specific forms of statements are allowed.
\todo[inline]{List of permissible statements.}

\section{Example}

\begin{listing}
\lstinputlisting{summation-kernel.pvl}
\caption{Summation using a kernel.}
\label{summation}
\end{listing}

In listing \ref{summation}, we have put specified and verified code
for computing the sum of the elements in an array using a kernel.
The idea is that for each element ofthe array, a thread atomically adds the
value to the total. To track the contribution of each thread to the total
this contribution is first set to $0$ and later set to $a[i]$. Thus as the invariant
is that the result is always equal to the sum of the contributions,
we can afterwards conclude that the result is the sum of the array
because the contributions are identical to the array elements.

\begin{listing}
\lstinputlisting{zero-many.pvl}
\caption{Initialise to zero.}
\label{zero-many}
\end{listing}

In \listref{zero-many}, we show how to initialise fields, arrays and matrices in parallel.

\section{Known Problems}

\subsection{Allowed use of variables}

Using local variables in blocks changes their allowed use.
If a local variable is used in an invariant then inside the invariant block it is invisible,
except in atomic blocks that synchonize on the invariant.
If a local variable is syntactically used in more than one thread of a
parallel block then it may be read at arbitrary position
in the parallel block, and can be written in barrier
statements.

These default rules restrict local variables to be used by either an invariant
or a parallel block but not both. To overcome this restriction, we can share local
variables in a block. For example, the following validates
\begin{lstlisting}
int x; // x is local variable
share(x){ // x is shared variable
  assert Perm(x,1);
}
\end{lstlisting}

\subsection{Barrier Specifications}

Barriers are specified by writing a contract that requires
all of the permissions that are given up by the threads
during the barrier and ensures all of the redistributed permissions
available after the barrier completed.

A possible short-hand when $i$ is an index is
\begin{lstlisting}
send R(i) to id(i);
\end{lstlisting}
Which stands for
\begin{lstlisting}
requires R(i);
ensures (\forall* int j; i == id(j) ; R(j));
\end{lstlisting}

Barriers are encoded using the two method encoding pattern.
When a barrier has been annotated with send's only
and the statement it executes cannot gain or loose permissions
then
\begin{lstlisting}
barrier(){
  send R1(i) to id1(i);
  send R2(i) to id2(i);
  S;
}
\end{lstlisting}
can safely be encoded as
\begin{lstlisting}
assert R1(i) ** R2(i);
inhale (\forall* int j ; j != i ; R1(j));
inhale (\forall* int j ; j != i ; R2(j));
S;
exhale (\forall* int j ; id1(j) != i ; R1(j));
exhale (\forall* int j ; id2(j) != i ; R2(j));
\end{lstlisting}

